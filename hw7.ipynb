{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad362e02",
   "metadata": {},
   "source": [
    "# GMO Forecasting\n",
    "\n",
    "*Case: Grantham, Mayo, and Van Otterloo, 2012: Estimating the Equity Risk Premium\n",
    "[9-211-051].*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\E}{\\mathbb{E}}\n",
    "\\newcommand{\\cond}{\\, |\\, }\n",
    "\\newcommand{\\var}{\\text{var}}\n",
    "\\newcommand{\\cov}{\\text{cov}}\n",
    "\\newcommand{\\corr}{\\text{corr}}\n",
    "\\newcommand{\\std}{\\text{std}}\n",
    "\\newcommand{\\covmat}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\cdf}{\\Phi}\n",
    "\\newcommand{\\Normal}{\\mathcal{N}}\n",
    "\\newcommand{\\lp}{\\mathbb{L}}\n",
    "\\newcommand{\\dlim}{\\overset{D}{\\to \\;}}\n",
    "\\newcommand{\\plim}{\\overset{P}{\\to \\;}}\n",
    "\\newcommand{\\iid}{i.i.d.}\n",
    "\\newcommand{\\free}{f}\n",
    "\\newcommand{\\ex}[1]{\\tilde{#1}}\n",
    "\\newcommand{\\R}[1][]{R^{#1}}\n",
    "\\newcommand{\\Rf}{\\R[\\free]}\n",
    "\\newcommand{\\Rx}[1][]{\\ex{R}^{#1}}\n",
    "\\renewcommand{\\r}[1][]{r^{\\scriptscriptstyle {#1}}}\n",
    "\\newcommand{\\rf}{\\r[\\free]}\n",
    "\\newcommand{\\rx}[1][]{\\ex{r}^{\\scriptscriptstyle {#1}}}\n",
    "\\newcommand{\\rlog}[1][]{{\\texttt{r}^{#1}}}\n",
    "\\newcommand{\\rflog}{\\rlog[\\free]}\n",
    "\\newcommand{\\rvec}[1][]{\\boldsymbol{\\r[#1]}}\n",
    "\\newcommand{\\rxvec}[1][]{\\boldsymbol{\\rx[#1]}}\n",
    "\\newcommand{\\pay}[1][]{\\Gamma^{\\scriptscriptstyle {#1}}}\n",
    "\\renewcommand{\\P}{\\mathcal{P}}\n",
    "\\newcommand{\\ind}[1]{_{[#1]}}\n",
    "\\newcommand{\\notind}[1]{\\ind{-#1}}\n",
    "\\newcommand{\\coord}{\\boldsymbol{\\iota}}\n",
    "\\newcommand{\\obs}{n}\n",
    "\\newcommand{\\Nobs}{N}\n",
    "\\newcommand{\\lag}{h}\n",
    "\\newcommand{\\Nlag}{H}\n",
    "\\newcommand{\\indx}{i}\n",
    "\\newcommand{\\indxalt}{j}\n",
    "\\newcommand{\\I}{\\mathcal{I}}\n",
    "\\newcommand{\\one}{\\textbf{1}}\n",
    "\\newcommand{\\zeros}{\\textbf{0}}\n",
    "\\newcommand{\\x}{\\textbf{x}}\n",
    "\\newcommand{\\z}{\\textbf{z}}\n",
    "\\newcommand{\\y}{\\textbf{y}}\n",
    "\\newcommand{\\w}{\\textbf{w}}\n",
    "\\newcommand{\\X}{\\textbf{X}}\n",
    "\\newcommand{\\Z}{\\textbf{Z}}\n",
    "\\newcommand{\\Y}{\\textbf{Y}}\n",
    "\\newcommand{\\W}{\\textbf{W}}\n",
    "\\newcommand{\\alphavec}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\betavec}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\epsilonvec}{\\boldsymbol{\\epsilon}}\n",
    "\\newcommand{\\sigmavec}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\mux}{\\ex{\\mu}}\n",
    "\\newcommand{\\muvec}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\muxvec}{\\boldsymbol{\\ex{\\mu}}}\n",
    "\\newcommand{\\muP}{\\mu^p}\n",
    "\\newcommand{\\Sigmamat}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\wt}{\\boldsymbol{\\omega}}\n",
    "\\newcommand{\\wtx}{\\boldsymbol{w}}\n",
    "\\newcommand{\\wtxstar}{\\wtx^*}\n",
    "\\newcommand{\\wtTan}{\\wt^{\\tan}}\n",
    "\\newcommand{\\wtxTan}{\\wtx^{\\tan}}\n",
    "\\newcommand{\\wtGMV}{\\wt^{\\gmv}}\n",
    "\\newcommand{\\mv}{\\scriptscriptstyle {\\subset}}\n",
    "\\newcommand{\\MV}{$\\ex{\\text{MV}}\\ $}\n",
    "\\newcommand{\\MVscale}{\\delta}\n",
    "\\newcommand{\\ifac}{k}\n",
    "\\newcommand{\\Nfacs}{k}\n",
    "\\newcommand{\\fbeta}[1][]{\\beta^{\\scriptscriptstyle {#1}}}\n",
    "\\newcommand{\\fbetavec}[1][]{\\betavec^{\\scriptscriptstyle {#1}}}\n",
    "\\newcommand{\\radon}{q}\n",
    "\\newcommand{\\mkt}{m}\n",
    "\\newcommand{\\act}{a}\n",
    "\\renewcommand{\\tan}{\\texttt{t}}\n",
    "\\newcommand{\\gmv}{\\texttt{v}}\n",
    "\\newcommand{\\size}{s}\n",
    "\\newcommand{\\val}{v}\n",
    "\\newcommand{\\up}{u}\n",
    "\\newcommand{\\mom}{\\text{mom}}\n",
    "\\newcommand{\\orthog}{\\alpha}\n",
    "\\newcommand{\\fac}{z}\n",
    "\\newcommand{\\facs}{\\boldsymbol{z}}\n",
    "\\newcommand{\\facmac}{f}\n",
    "\\newcommand{\\facsmac}{\\boldsymbol{f}}\n",
    "\\newcommand{\\prem}{\\lambda}\n",
    "\\newcommand{\\premvec}{\\boldsymbol{\\prem}}\n",
    "\\newcommand{\\pos}{i}\n",
    "\\newcommand{\\hedge}{j}\n",
    "\\newcommand{\\etavec}{\\boldsymbol{\\eta}}\n",
    "\\newcommand{\\Q}{\\textbf{Q}}\n",
    "\\newcommand{\\eig}{\\psi}\n",
    "\\newcommand{\\Eig}{\\Psi}\n",
    "\\newcommand{\\eigv}{\\textbf{q}}\n",
    "\\newcommand{\\Eigv}{Q}\n",
    "\\newcommand{\\PCwt}{\\textbf{q}}\n",
    "\\newcommand{\\PCfac}{x}\n",
    "\\newcommand{\\VaR}{\\text{VaR}}\n",
    "\\newcommand{\\ES}{\\text{ES}}\n",
    "\\newcommand{\\Rrate}{\\,\\r}\n",
    "\\newcommand{\\Rratevec}{\\,\\rvec}\n",
    "\\newcommand{\\RVaR}{\\, \\r[\\text{VaR}]}\n",
    "\\newcommand{\\RES}{\\,\\r[\\text{ES}]}\n",
    "\\newcommand{\\rVaR}{\\, \\r[\\text{VaR}]}\n",
    "\\newcommand{\\rES}{\\, \\r[\\text{ES}]}\n",
    "\\newcommand{\\thresh}{\\pi}\n",
    "\\newcommand{\\quantile}{\\texttt{z}_{\\thresh}}\n",
    "\\newcommand{\\gain}{\\Delta V}\n",
    "\\newcommand{\\loss}{L}\n",
    "\\newcommand{\\lossvec}{\\textbf{L}}\n",
    "\\newcommand{\\cdfnorm}{\\Phi}\n",
    "\\newcommand{\\cdflosst}{F^\\ell_\\tau}\n",
    "\\newcommand{\\cdfgaint}{F^g_\\tau}\n",
    "\\newcommand{\\cdfretst}{F^{\\r}_\\tau}\n",
    "\\newcommand{\\invcdflosst}{F_\\tau^{\\ell(-1)}}\n",
    "\\newcommand{\\invcdfgaint}{F_\\tau^{g[-1]}}\n",
    "\\newcommand{\\invcdfretst}{F^{\\r(-1)}_\\tau}\n",
    "\\newcommand{\\mawt}{\\theta}\n",
    "\\newcommand{\\DP}{\\text{DP}}\n",
    "\\newcommand{\\n}{{(n)}}\n",
    "\\newcommand{\\0}{(0)}\n",
    "\\newcommand{\\1}{{(1)}}\n",
    "\\newcommand{\\2}{{(2)}}\n",
    "\\newcommand{\\3}{{(3)}}\n",
    "\\newcommand{\\4}{{(4)}}\n",
    "\\newcommand{\\5}{{(5)}}\n",
    "\\newcommand{\\bonds}{B}\n",
    "\\newcommand{\\fx}{S}\n",
    "\\newcommand{\\fxlog}{\\texttt{s}}\n",
    "\\newcommand{\\meuro}{\\text{\\euro}}\n",
    "\\newcommand{\\usd}{\\$}\n",
    "\\newcommand{\\for}{F}\n",
    "\\newcommand{\\forlog}{\\texttt{f}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 READING: GMO\n",
    "\n",
    "This section is not graded, and you do not need to submit your answers. But you are expected to consider these issues and be ready to discuss them.\n",
    "\n",
    "1. **GMO’s approach.**\n",
    "   - Why does GMO believe they can more easily predict **long‑run** than **short‑run** asset‑class performance?\n",
    "      - Long run is more driven by 'fundamentals' and short run is more by popularity which is harder to predict\n",
    "   - What predicting variables does the case mention are used by GMO? Does this fit with the goal of long‑run forecasts?\n",
    "      - They use dividend yield, changes in P/E multiples, changes in profit margins, and growth in sales per share. These variables are fundamental drivers that revert over time, so they align well with long-horizon forecasts.\n",
    "   - How has this approach led to **contrarian** positions?\n",
    "      - When valuations or margins deviate from historical norms, GMO underweights overpriced asset classes and overweights depressed ones.\n",
    "   - How does this approach raise **business risk** and **managerial career risk**?\n",
    "      - Because GMO often takes unpopular positions, they can underperform for long stretches while the market stays irrational.This creates business and career risk because clients may withdraw funds or fire managers when they deviate too far from the herd.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313be0bb",
   "metadata": {},
   "source": [
    "2. **The market environment.**\n",
    "   - We often estimate the market risk premium by looking at a large sample of historic data. What reasons does the case give to be skeptical that the market risk premium will be as high **in the future** as it has been **over the past 50 years**?\n",
    "      - Historical equity returns were boosted by unusually high starting dividend yields, strong valuation tailwinds, and rising profit margins,conditions unlikely to repeat.  The case argues that today’s higher valuations and already-elevated margins imply lower future returns than the exceptional past 50 years. \n",
    "   - In 2007, GMO forecasts **real excess equity returns** will be negative. What are the biggest drivers of their **pessimistic conditional** forecast relative to the **unconditional** forecast? (See Exhibit 9.)\n",
    "      - GMO expected P/E ratios and profit margins to fall sharply from extremely elevated levels, creating large negative contributions to expected returns. These mean-reversion effects overwhelmed the normal long-run components (dividends and sales growth), driving the conditional forecast far below the unconditional steady-state forecast. \n",
    "   - In the 2011 forecast, what components has GMO revised most relative to 2007? Now how does their conditional forecast compare to the unconditional? (See Exhibit 10.)\n",
    "      - By 2011, valuations were lower and margins only moderately above normal, so the expected compression in P/Es and margins was far smaller than in 2007. As a result, the conditional forecast is now close to,and only slightly below,the unconditional forecast, rather than dramatically worse as it was in 2007. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdb0d31",
   "metadata": {},
   "source": [
    "3. **Consider the asset‑class forecasts in Exhibit 1.**\n",
    "   - Which asset class did GMO estimate to have a **negative 10‑year return** over 2002–2011?\n",
    "      - GMO forecasted U.S. equities (S&P 500) to have a slightly negative 10-year real return. This is visible in Exhibit 1, where the S&P 500 bar is below zero in the forecast.\n",
    "   - Which asset classes substantially **outperformed** GMO’s estimate over that time period?\n",
    "      - U.S. REITs, emerging-market equities, and emerging-market debt delivered realized returns far above GMO’s projections. All three ended up many percentage points above their forecast bars in Exhibit 1\n",
    "   - Which asset classes substantially **underperformed** GMO’s estimate over that time period?\n",
    "      - U.S. small stocks, international small caps, and EAFE equities significantly underperformed GMO’s expectations. Their realized returns fell well short of the forecasted levels shown in Exhibit 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95da3095",
   "metadata": {},
   "source": [
    "4. **Fund performance.**\n",
    "   - In which asset class was **GMWAX** most heavily allocated throughout the majority of 1997–2011?\n",
    "      - GMWAX was most heavily allocated to U.S. equities for the majority of the 1997–2011 period. Exhibit 3 shows U.S. stocks consistently occupying the largest share of the portfolio. \n",
    "   - Comment on the performance of GMWAX versus its benchmark. (No calculation needed; simply comment on the comparison in the exhibits.)\n",
    "      - GMWAX generally outperformed its benchmark over the period, delivering higher excess returns. It also did so with lower volatility, giving it a much stronger risk-adjusted performance than the benchmark.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aceb25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c0f83d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/gmo_analysis_data.xlsx\"\n",
    "\n",
    "signals = pd.read_excel(file, sheet_name=\"signals\", parse_dates=[\"date\"])\n",
    "rf = pd.read_excel(file, sheet_name=\"risk-free rate\", parse_dates=[\"date\"])\n",
    "rets = pd.read_excel(file, sheet_name=\"total returns\", parse_dates=[\"date\"])\n",
    "\n",
    "signals = signals.set_index(\"date\")\n",
    "rf = rf.set_index(\"date\")\n",
    "rets = rets.set_index(\"date\")\n",
    "\n",
    "rf[\"rf_monthly\"] = (1 + rf[\"TBill 3M\"] / 12) - 1\n",
    "df = rets.join(rf[\"rf_monthly\"], how=\"inner\")\n",
    "df[\"GMWAX_excess\"] = df[\"GMWAX\"] - df[\"rf_monthly\"]\n",
    "\n",
    "\n",
    "def perf_stats(series):\n",
    "    mean = series.mean()\n",
    "    vol = series.std()\n",
    "    sharpe = mean / vol if vol != 0 else np.nan\n",
    "    return mean, vol, sharpe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Analyzing GMO\n",
    "\n",
    "_This section utilizes data in the file `gmo_data.xlsx`._ Convert total returns to **excess returns** using the risk‑free rate.\n",
    "\n",
    "1. **Performance (GMWAX).** Compute **mean**, **volatility**, and **Sharpe ratio** for **GMWAX** over three samples:\n",
    "   - inception → 2011\n",
    "   - 2012 → present\n",
    "   - inception → present  \n",
    "   Has the mean, vol, and Sharpe changed much since the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dee34c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMWAX Excess Return Performance\n",
      "--------------------------------\n",
      "Inception → 2011:\n",
      "  Mean:   0.0039\n",
      "  Vol:    0.0319\n",
      "  Sharpe: 0.1213\n",
      "\n",
      "2012 → Present:\n",
      "  Mean:   0.0041\n",
      "  Vol:    0.0267\n",
      "  Sharpe: 0.1531\n",
      "\n",
      "Inception → Present:\n",
      "  Mean:   0.0040\n",
      "  Vol:    0.0295\n",
      "  Sharpe: 0.1348\n"
     ]
    }
   ],
   "source": [
    "inception = df.index.min()\n",
    "cut_2012 = pd.Timestamp(\"2012-01-01\")\n",
    "\n",
    "sample1 = df.loc[:cut_2012][\"GMWAX_excess\"]\n",
    "sample2 = df.loc[cut_2012:][\"GMWAX_excess\"]\n",
    "sample3 = df[\"GMWAX_excess\"]\n",
    "\n",
    "stats1 = perf_stats(sample1)\n",
    "stats2 = perf_stats(sample2)\n",
    "stats3 = perf_stats(sample3)\n",
    "\n",
    "print(\"GMWAX Excess Return Performance\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Inception → 2011:\")\n",
    "print(f\"  Mean:   {stats1[0]:.4f}\")\n",
    "print(f\"  Vol:    {stats1[1]:.4f}\")\n",
    "print(f\"  Sharpe: {stats1[2]:.4f}\")\n",
    "\n",
    "print(\"\\n2012 → Present:\")\n",
    "print(f\"  Mean:   {stats2[0]:.4f}\")\n",
    "print(f\"  Vol:    {stats2[1]:.4f}\")\n",
    "print(f\"  Sharpe: {stats2[2]:.4f}\")\n",
    "\n",
    "print(\"\\nInception → Present:\")\n",
    "print(f\"  Mean:   {stats3[0]:.4f}\")\n",
    "print(f\"  Vol:    {stats3[1]:.4f}\")\n",
    "print(f\"  Sharpe: {stats3[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6be6668",
   "metadata": {},
   "source": [
    "The mean excess return and Sharpe ratio are very similar to the pre-2011 sample in the case, but volatility has declined somewhat, which slightly improves the post-2012 Sharpe ratio. Overall, GMWAX’s performance profile has not changed dramatically since the case, returns are still modestly positive with moderate vol and a low but stable Sharpe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa18eba6",
   "metadata": {},
   "source": [
    "2. **Tail risk (GMWAX).** For all three samples, analyze extreme scenarios:\n",
    "   - minimum return\n",
    "   - 5th percentile (VaR‑5th)\n",
    "   - maximum drawdown (compute on **total** returns, not excess returns)  \n",
    "   (a) Does GMWAX have high or low tail‑risk as seen by these stats?  \n",
    "   (b) Does that vary much across the two subsamples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b7067ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception–2011: -0.14915005798542078 -0.04400285930355574 -0.2936139850160543\n",
      "2012–Present: -0.11501764081673713 -0.039814152754950316 -0.21679520137103694\n",
      "Inception–Present: -0.14915005798542078 -0.041147204159103404 -0.2936139850160543\n"
     ]
    }
   ],
   "source": [
    "cut = pd.Timestamp(\"2012-01-01\")\n",
    "\n",
    "s1 = df.loc[:cut]\n",
    "s2 = df.loc[cut:]\n",
    "s3 = df\n",
    "\n",
    "def mdd(x):\n",
    "    w = (1 + x).cumprod()\n",
    "    return ((w - w.cummax()) / w.cummax()).min()\n",
    "\n",
    "mins = [s1[\"GMWAX_excess\"].min(),\n",
    "        s2[\"GMWAX_excess\"].min(),\n",
    "        s3[\"GMWAX_excess\"].min()]\n",
    "\n",
    "p5s = [np.percentile(s1[\"GMWAX_excess\"], 5),\n",
    "       np.percentile(s2[\"GMWAX_excess\"], 5),\n",
    "       np.percentile(s3[\"GMWAX_excess\"], 5)]\n",
    "\n",
    "mdds = [mdd(s1[\"GMWAX\"]),\n",
    "        mdd(s2[\"GMWAX\"]),\n",
    "        mdd(s3[\"GMWAX\"])]\n",
    "\n",
    "print(\"Inception–2011:\", mins[0], p5s[0], mdds[0])\n",
    "print(\"2012–Present:\",  mins[1], p5s[1], mdds[1])\n",
    "print(\"Inception–Present:\", mins[2], p5s[2], mdds[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b9d82",
   "metadata": {},
   "source": [
    "(a) GMWAX shows meaningful tail-risk: its minimum monthly excess returns are large negatives (–11% to –15%), and its maximum drawdowns are very deep (around –29%). These values indicate substantial downside exposure, consistent with an equity-heavy fund.\n",
    "(b) Tail-risk is somewhat lower after 2012, with a smaller worst month, a slightly less severe 5th percentile, and a shallower drawdown (–22% vs. –29%). But the differences are modest, GMWAX remained exposed to large negative shocks in both periods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef0467",
   "metadata": {},
   "source": [
    "3. **Market exposure (GMWAX).** For all three samples, regress **excess returns of GMWAX** on **excess returns of SPY**:\n",
    "   - report estimated **alpha**, **beta**, and **R²**\n",
    "   - is GMWAX a **low‑beta** strategy? has that changed since the case?\n",
    "   - does GMWAX provide **alpha**? has that changed across subsamples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4303f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception–2011: (np.float64(0.0022500334583120066), np.float64(0.5421276478300552), np.float64(0.6486862668726975))\n",
      "2012–Present: (np.float64(-0.0022801320915483373), np.float64(0.5669136067436911), np.float64(0.7309037234315912))\n",
      "Inception–Present: (np.float64(0.00017929453464121783), np.float64(0.5474517195946391), np.float64(0.675236474844338))\n"
     ]
    }
   ],
   "source": [
    "df[\"SPY_excess\"] = df[\"SPY\"] - df[\"rf_monthly\"]\n",
    "\n",
    "cut = pd.Timestamp(\"2012-01-01\")\n",
    "s1 = df.loc[:cut]\n",
    "s2 = df.loc[cut:]\n",
    "s3 = df\n",
    "\n",
    "def reg(sample):\n",
    "    y = sample[\"GMWAX_excess\"]\n",
    "    x = sample[\"SPY_excess\"]\n",
    "    X = sm.add_constant(x)\n",
    "    m = sm.OLS(y, X).fit()\n",
    "    alpha = m.params[\"const\"]\n",
    "    beta = m.params[\"SPY_excess\"]\n",
    "    r2 = m.rsquared\n",
    "    return alpha, beta, r2\n",
    "\n",
    "r1 = reg(s1)\n",
    "r2 = reg(s2)\n",
    "r3 = reg(s3)\n",
    "\n",
    "print(\"Inception–2011:\", r1)\n",
    "print(\"2012–Present:\",  r2)\n",
    "print(\"Inception–Present:\", r3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15a632",
   "metadata": {},
   "source": [
    "- Yes,  GMWAX has a beta around 0.55, well below 1, meaning it behaves like a low-beta, defensive equity allocation. Its beta has been stable across subsamples (0.54 → 0.57), so its market exposure has not changed meaningfully since the period discussed in the case.\n",
    "- Before 2012, GMWAX produced a positive monthly alpha (~0.22%), but after 2012 alpha turns slightly negative (~–0.23%). This means any historical alpha has not persisted, and over the full sample the strategy’s alpha is effectively zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e40f3",
   "metadata": {},
   "source": [
    "4. **Compare to GMGEX.** Repeat items 1–3 for **GMGEX**. What are key differences between the two strategies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59cf0def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMGEX Performance\n",
      "Inception–2011: (np.float64(-0.00031859204256870515), np.float64(0.042508310652610175), np.float64(-0.007494817782158614))\n",
      "2012–Present: (np.float64(0.001098464586537471), np.float64(0.06584006396291156), np.float64(0.01668383231152765))\n",
      "Inception–Present: (np.float64(0.00035930824685960976), np.float64(0.054843098636164336), np.float64(0.006551567212554921))\n"
     ]
    }
   ],
   "source": [
    "## Performance\n",
    "\n",
    "df[\"GMGEX_excess\"] = df[\"GMGEX\"] - df[\"rf_monthly\"]\n",
    "\n",
    "def perf_stats(x):\n",
    "    m = x.mean()\n",
    "    v = x.std()\n",
    "    s = m/v\n",
    "    return m, v, s\n",
    "\n",
    "cut = pd.Timestamp(\"2012-01-01\")\n",
    "s1 = df.loc[:cut][\"GMGEX_excess\"]\n",
    "s2 = df.loc[cut:][\"GMGEX_excess\"]\n",
    "s3 = df[\"GMGEX_excess\"]\n",
    "\n",
    "print(\"GMGEX Performance\")\n",
    "print(\"Inception–2011:\", perf_stats(s1))\n",
    "print(\"2012–Present:\",  perf_stats(s2))\n",
    "print(\"Inception–Present:\", perf_stats(s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "986f8bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMGEX Tail Risk\n",
      "Inception–2011: -0.15159189151599428 -0.08229182103321031 -0.5556303549571604\n",
      "2012–Present: -0.6588630776718837 -0.06560264996672513 -0.7373641946150212\n",
      "Inception–Present: -0.6588630776718837 -0.0757370755059067 -0.7618115055079558\n"
     ]
    }
   ],
   "source": [
    "## Tail risk\n",
    "\n",
    "cut = pd.Timestamp(\"2012-01-01\")\n",
    "\n",
    "s1 = df.loc[:cut]\n",
    "s2 = df.loc[cut:]\n",
    "s3 = df\n",
    "\n",
    "def mdd(x):\n",
    "    w = (1 + x).cumprod()\n",
    "    return ((w - w.cummax()) / w.cummax()).min()\n",
    "\n",
    "mins = [s1[\"GMGEX_excess\"].min(),\n",
    "        s2[\"GMGEX_excess\"].min(),\n",
    "        s3[\"GMGEX_excess\"].min()]\n",
    "\n",
    "p5s = [np.percentile(s1[\"GMGEX_excess\"], 5),\n",
    "       np.percentile(s2[\"GMGEX_excess\"], 5),\n",
    "       np.percentile(s3[\"GMGEX_excess\"], 5)]\n",
    "\n",
    "mdds = [mdd(s1[\"GMGEX\"]),\n",
    "        mdd(s2[\"GMGEX\"]),\n",
    "        mdd(s3[\"GMGEX\"])]\n",
    "\n",
    "print(\"GMGEX Tail Risk\")\n",
    "print(\"Inception–2011:\", mins[0], p5s[0], mdds[0])\n",
    "print(\"2012–Present:\",  mins[1], p5s[1], mdds[1])\n",
    "print(\"Inception–Present:\", mins[2], p5s[2], mdds[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04ad5a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMGEX Market Exposure\n",
      "Inception–2011: (np.float64(-0.0026001177205105474), np.float64(0.7642370576841833), np.float64(0.7258976656983878))\n",
      "2012–Present: (np.float64(-0.008138868124506994), np.float64(0.8212574135570367), np.float64(0.2531710354998814))\n",
      "Inception–Present: (np.float64(-0.005063656389201239), np.float64(0.7816327959221827), np.float64(0.39840288728573403))\n"
     ]
    }
   ],
   "source": [
    "## Market Exposure\n",
    "\n",
    "df[\"SPY_excess\"] = df[\"SPY\"] - df[\"rf_monthly\"]\n",
    "\n",
    "cut = pd.Timestamp(\"2012-01-01\")\n",
    "s1 = df.loc[:cut]\n",
    "s2 = df.loc[cut:]\n",
    "s3 = df\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def reg(sample):\n",
    "    y = sample[\"GMGEX_excess\"]\n",
    "    x = sample[\"SPY_excess\"]\n",
    "    X = sm.add_constant(x)\n",
    "    m = sm.OLS(y, X).fit()\n",
    "    return m.params[\"const\"], m.params[\"SPY_excess\"], m.rsquared\n",
    "\n",
    "print(\"GMGEX Market Exposure\")\n",
    "print(\"Inception–2011:\", reg(s1))\n",
    "print(\"2012–Present:\",  reg(s2))\n",
    "print(\"Inception–Present:\", reg(s3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2507b47",
   "metadata": {},
   "source": [
    "- GMWAX is a low-beta, defensive allocation strategy with moderate volatility, relatively mild drawdowns, and historically small but positive risk-adjusted performance.\n",
    "- GMGEX, by contrast, has a much higher beta, far larger drawdowns, and substantially higher volatility, making it behave more like an aggressive global-equity portfolio.\n",
    "- GMWAX’s alpha has declined over time but is roughly zero overall, whereas GMGEX shows consistently negative alpha in every subsample.\n",
    "- Overall, GMWAX offers steady, lower-risk market exposure, while GMGEX delivers higher risk with weaker performance and much worse downside protection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Forecast Regressions\n",
    "\n",
    "_This section utilizes data in `gmo_data.xlsx`._\n",
    "\n",
    "1. **Lagged regression.** Consider the regression with predictors lagged one period:\n",
    "\n",
    "$$\n",
    "r^{SPY}_{t} \\;=\\; \\alpha^{SPY,X} \\;+\\; \\big(\\beta^{SPY,X}\\big)^\\prime X_{t-1} \\;+\\; \\epsilon^{SPY,X}_{t}\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "Estimate (1) and report the **$R^2$**, as well as the OLS estimates for $\\alpha$ and $\\beta$. Do this for:\n",
    "   - $X$ as a single regressor, the **dividend–price** ratio ($DP$)\n",
    "   - $X$ as a single regressor, the **earnings–price** ratio ($EP$)\n",
    "   - $X$ with **three** regressors: $DP$, $EP$, and the **10‑year yield**  \n",
    "   For each, report the **$R^2$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eddd941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP: (const    -0.007793\n",
      "DP_lag    0.928617\n",
      "dtype: float64, np.float64(0.007262714234388512))\n",
      "EP: (const    -0.004074\n",
      "EP_lag    0.240449\n",
      "dtype: float64, np.float64(0.00482727781750536))\n",
      "DP, EP, TNote: (const    -0.002655\n",
      "DP_lag    0.445540\n",
      "EP_lag    0.142754\n",
      "TN_lag   -0.117296\n",
      "dtype: float64, np.float64(0.008637555438353095))\n"
     ]
    }
   ],
   "source": [
    "# merge signals with returns\n",
    "z = df.join(signals[[\"SPX D/P\",\"SPX E/P\",\"T-Note 10YR\"]], how=\"inner\")\n",
    "\n",
    "# lag predictors\n",
    "z[\"DP_lag\"] = z[\"SPX D/P\"].shift(1)\n",
    "z[\"EP_lag\"] = z[\"SPX E/P\"].shift(1)\n",
    "z[\"TN_lag\"] = z[\"T-Note 10YR\"].shift(1)\n",
    "\n",
    "# drop first NA row\n",
    "z = z.dropna()\n",
    "\n",
    "y = z[\"SPY\"]  # monthly SPY total return\n",
    "\n",
    "def run_reg(X):\n",
    "    X = sm.add_constant(X)\n",
    "    m = sm.OLS(y, X).fit()\n",
    "    return m.params, m.rsquared\n",
    "\n",
    "# 1. SPY on lagged DP\n",
    "res_dp = run_reg(z[[\"DP_lag\"]])\n",
    "\n",
    "# 2. SPY on lagged EP\n",
    "res_ep = run_reg(z[[\"EP_lag\"]])\n",
    "\n",
    "# 3. SPY on lagged DP, EP, 10-year yield\n",
    "res_three = run_reg(z[[\"DP_lag\",\"EP_lag\",\"TN_lag\"]])\n",
    "\n",
    "print(\"DP:\", res_dp)\n",
    "print(\"EP:\", res_ep)\n",
    "print(\"DP, EP, TNote:\", res_three)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a2fdce",
   "metadata": {},
   "source": [
    "2. **Trading strategy from forecasts.** For each of the three regressions:\n",
    "   - Build the forecasted SPY return: $\\hat r^{SPY}_{t+1}$ (forecast made using $X_t$ to predict $r^{SPY}_{t+1}$).\n",
    "   - Set the scale (portfolio weight) to $w_t = 100 \\,\\hat r^{SPY}_{t+1}$.\n",
    "   - Strategy return: $r^x_{t+1} = w_t\\, r^{SPY}_{t+1}$.  \n",
    "   For each strategy, compute:\n",
    "   - mean, volatility, Sharpe\n",
    "   - max drawdown\n",
    "   - market **alpha**\n",
    "   - market **beta**\n",
    "   - market **information ratio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5a6d5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP strategy: {'alpha': np.float64(0.0006398956003638714), 'beta': np.float64(0.970589716767053), 'R2_forecast': np.float64(0.007262714234388512), 'mean': np.float64(0.007470731430706395), 'vol': np.float64(0.04864474018415035), 'sharpe': np.float64(0.1535773734719328), 'mdd': np.float64(-0.6986154810238331), 'info': np.float64(0.028155689872469428)}\n",
      "EP strategy: {'alpha': np.float64(0.0003203503718828169), 'beta': np.float64(0.9482566970549118), 'R2_forecast': np.float64(0.00482727781750536), 'mean': np.float64(0.006994010426906408), 'vol': np.float64(0.044911900764534815), 'sharpe': np.float64(0.15572733079311812), 'mdd': np.float64(-0.6168412971491661), 'info': np.float64(0.02020288852661786)}\n",
      "DP+EP+10Y: {'alpha': np.float64(0.0009552526311245639), 'beta': np.float64(0.9640193991106654), 'R2_forecast': np.float64(0.008637555438353095), 'mean': np.float64(0.007739847747714752), 'vol': np.float64(0.0483356237192173), 'sharpe': np.float64(0.16012719299280584), 'mdd': np.float64(-0.6660694731021486), 'info': np.float64(0.04223724901329584)}\n"
     ]
    }
   ],
   "source": [
    "# merge signals into df\n",
    "z = df.join(signals[[\"SPX D/P\", \"SPX E/P\", \"T-Note 10YR\"]], how=\"inner\")\n",
    "\n",
    "z[\"SPY_fwd\"] = z[\"SPY\"].shift(-1)\n",
    "z[\"rf_fwd\"] = z[\"rf_monthly\"].shift(-1)\n",
    "z = z.dropna(subset=[\"SPY_fwd\", \"rf_fwd\"])\n",
    "\n",
    "def strat_from_X(Xcols):\n",
    "    X = z[Xcols]\n",
    "    y = z[\"SPY_fwd\"]\n",
    "    Xc = sm.add_constant(X)\n",
    "    m = sm.OLS(y, Xc).fit()\n",
    "\n",
    "    rhat = m.predict(Xc)\n",
    "    w = 100 * rhat\n",
    "    rx = w * y\n",
    "    rx_excess = rx - z[\"rf_fwd\"]\n",
    "\n",
    "    mkt_excess = z[\"SPY_fwd\"] - z[\"rf_fwd\"]\n",
    "    mkt_excess.name = \"SPY_excess_fwd\"\n",
    "\n",
    "    mean = rx_excess.mean()\n",
    "    vol = rx_excess.std()\n",
    "    sharpe = mean / vol\n",
    "\n",
    "    wealth = (1 + rx).cumprod()\n",
    "    peak = wealth.cummax()\n",
    "    mdd = ((wealth - peak) / peak).min()\n",
    "\n",
    "    Xm = sm.add_constant(mkt_excess)\n",
    "    reg = sm.OLS(rx_excess, Xm).fit()\n",
    "    alpha = reg.params[\"const\"]\n",
    "    beta = reg.params[\"SPY_excess_fwd\"]\n",
    "    te = reg.resid.std()\n",
    "    info = alpha / te\n",
    "\n",
    "    return {\n",
    "        \"alpha\": alpha,\n",
    "        \"beta\": beta,\n",
    "        \"R2_forecast\": m.rsquared,\n",
    "        \"mean\": mean,\n",
    "        \"vol\": vol,\n",
    "        \"sharpe\": sharpe,\n",
    "        \"mdd\": mdd,\n",
    "        \"info\": info\n",
    "    }\n",
    "\n",
    "res_dp   = strat_from_X([\"SPX D/P\"])\n",
    "res_ep   = strat_from_X([\"SPX E/P\"])\n",
    "res_3    = strat_from_X([\"SPX D/P\", \"SPX E/P\", \"T-Note 10YR\"])\n",
    "\n",
    "print(\"DP strategy:\",   res_dp)\n",
    "print(\"EP strategy:\",   res_ep)\n",
    "print(\"DP+EP+10Y:\",     res_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32913f4d",
   "metadata": {},
   "source": [
    "3. **Risk characteristics.**\n",
    "   - For both strategies, the market, and GMO, compute monthly **VaR** at $\\pi = 0.05$ (use the historical quantile).\n",
    "   - The case mentions stocks under‑performed short‑term bonds from 2000–2011. Does the dynamic portfolio above under‑perform the risk‑free rate over this time?\n",
    "   - Based on the regression estimates, in how many periods do we estimate a **negative risk premium**?\n",
    "   - Do you believe the dynamic strategy takes on **extra risk**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40257c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR_5 (monthly, total returns)\n",
      "DP strategy: -0.06154457123158455\n",
      "EP strategy: -0.06414378394464915\n",
      "Market (SPY): -0.07442817951315703\n",
      "GMO (GMWAX): -0.04038561221646227\n"
     ]
    }
   ],
   "source": [
    "dp = \"SPX D/P\"\n",
    "ep = \"SPX E/P\"\n",
    "tn = \"T-Note 10YR\"\n",
    "\n",
    "# recompute z just to be safe\n",
    "z = df.join(signals[[dp, ep, tn]], how=\"inner\")\n",
    "z[\"SPY_fwd\"] = z[\"SPY\"].shift(-1)\n",
    "z[\"rf_fwd\"]  = z[\"rf_monthly\"].shift(-1)\n",
    "z = z.dropna(subset=[\"SPY_fwd\", \"rf_fwd\"])\n",
    "\n",
    "def strat_returns(Xcols):\n",
    "    X  = z[Xcols]\n",
    "    y  = z[\"SPY_fwd\"]\n",
    "    Xc = sm.add_constant(X)\n",
    "    m  = sm.OLS(y, Xc).fit()\n",
    "    rhat = m.predict(Xc)\n",
    "    w    = 100 * rhat\n",
    "    rx   = w * y              # total strategy return\n",
    "    return rx\n",
    "\n",
    "# strategy total returns\n",
    "rx_dp = strat_returns([dp])\n",
    "rx_ep = strat_returns([ep])\n",
    "\n",
    "# market and GMO total returns aligned to same t+1 horizon\n",
    "r_mkt = z[\"SPY_fwd\"]                      # SPY\n",
    "r_gmo = df.loc[z.index, \"GMWAX\"]          # GMWAX total returns at t\n",
    "\n",
    "# 5% historical VaR (quantile)\n",
    "VaR_dp  = np.quantile(rx_dp, 0.05)\n",
    "VaR_ep  = np.quantile(rx_ep, 0.05)\n",
    "VaR_mkt = np.quantile(r_mkt, 0.05)\n",
    "VaR_gmo = np.quantile(r_gmo, 0.05)\n",
    "\n",
    "print(\"VaR_5 (monthly, total returns)\")\n",
    "print(\"DP strategy:\", VaR_dp)\n",
    "print(\"EP strategy:\", VaR_ep)\n",
    "print(\"Market (SPY):\", VaR_mkt)\n",
    "print(\"GMO (GMWAX):\", VaR_gmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0678735",
   "metadata": {},
   "source": [
    "- Yes, because the forecasts are extremely weak and the strategy uses high leverage, its returns are volatile with deep drawdowns and small average gains. Over 2000–2011, this almost certainly results in lower performance than simply holding T-bills.\n",
    "- Since all three regressions have negative alphas and very small R², the fitted returns are negative in a large fraction of months, often close to half. In other words, the models frequently predict a negative equity premium.\n",
    "- Yes, the leverage rule $w_t = 100\\hat r_{t+1}$ causes extremely high volatility, large VaR, and drawdowns exceeding –60%. This is far riskier than either the market or GMO’s fund."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Out‑of‑Sample Forecasting\n",
    "\n",
    "_This section utilizes data in `gmo_data.xlsx`._ Focus on using **both** $DP$ and $EP$ as signals in (1). Compute **out‑of‑sample** ($OOS$) statistics:\n",
    "\n",
    "**Procedure (rolling OOS):**\n",
    "- Start at $t=60$.\n",
    "- Estimate (1) using data **through** time $t$.\n",
    "- Using the estimated parameters and $x_t$, compute the forecast for $t+1$:\n",
    "  \n",
    "  $$\n",
    "  \\hat r^{SPY}_{t+1} \\;=\\; \\hat \\alpha^{SPY,X}_t \\;+\\; \\big(\\hat \\beta^{SPY,X}_t\\big)^\\prime x_t\n",
    "  $$\n",
    "\n",
    "- Forecast error: $e^{forecast}_{t+1} = r^{SPY}_{t+1} - \\hat r^{SPY}_{t+1}$.\n",
    "- Move to $t=61$ and iterate.\n",
    "\n",
    "Also compute the **null** forecast and errors:\n",
    "\n",
    "$$\n",
    "\\bar r^{SPY}_{t+1} = \\frac{1}{t}\\sum_{i=1}^t r^{SPY}_i, \\qquad\n",
    "e^{null}_{t+1} = r^{SPY}_{t+1} - \\bar r^{SPY}_{t+1}.\n",
    "$$\n",
    "\n",
    "1. **Report the out‑of‑sample $R^2$**\n",
    "\n",
    "$$\n",
    "R^2_{OOS} \\;\\equiv\\; 1 - \\frac{\\sum_{i=61}^T \\big(e^{forecast}_i\\big)^2}{\\sum_{i=61}^T \\big(e^{null}_i\\big)^2}\n",
    "$$\n",
    "\n",
    "Did this forecasting strategy produce a positive $R^2_{OOS}$?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "266dc536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS R^2: -0.0507771651350315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "z = df.join(signals[[\"SPX D/P\", \"SPX E/P\"]], how=\"inner\")\n",
    "z[\"SPY_fwd\"] = z[\"SPY\"].shift(-1)\n",
    "z = z.dropna(subset=[\"SPY_fwd\"])\n",
    "\n",
    "y = z[\"SPY_fwd\"].values\n",
    "Xall = z[[\"SPX D/P\", \"SPX E/P\"]].values\n",
    "\n",
    "forecast_errs = []\n",
    "null_errs = []\n",
    "\n",
    "start = 60\n",
    "\n",
    "for t in range(start, len(z)-1):\n",
    "    y_train = y[:t]\n",
    "    X_train = Xall[:t]\n",
    "    X_train_c = sm.add_constant(X_train, has_constant=\"add\")\n",
    "\n",
    "    m = sm.OLS(y_train, X_train_c).fit()\n",
    "\n",
    "    X_t = sm.add_constant(Xall[t].reshape(1, -1), has_constant=\"add\")\n",
    "    yhat = m.predict(X_t)[0]\n",
    "\n",
    "    e_forecast = y[t] - yhat\n",
    "    forecast_errs.append(e_forecast)\n",
    "\n",
    "    rbar = y_train.mean()\n",
    "    e_null = y[t] - rbar\n",
    "    null_errs.append(e_null)\n",
    "\n",
    "forecast_errs = np.array(forecast_errs)\n",
    "null_errs = np.array(null_errs)\n",
    "\n",
    "R2_oos = 1 - (forecast_errs**2).sum() / (null_errs**2).sum()\n",
    "print(\"OOS R^2:\", R2_oos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1863e",
   "metadata": {},
   "source": [
    "No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db183e2",
   "metadata": {},
   "source": [
    "2. **Redo 3.2 with OOS forecasts.** How does the OOS strategy compare to the in‑sample version of 3.2?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aab85a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS DP+EP strategy:\n",
      "mean: 0.004107197230443409\n",
      "vol: 0.052651597069969684\n",
      "Sharpe: 0.07800707782871769\n",
      "max drawdown: -0.6804121811774168\n",
      "alpha: -0.0015775028950335405\n",
      "beta: 0.7798649921524443\n",
      "information ratio: -0.03877564575391462\n"
     ]
    }
   ],
   "source": [
    "z = df.join(signals[[\"SPX D/P\", \"SPX E/P\"]], how=\"inner\")\n",
    "z[\"SPY_fwd\"] = z[\"SPY\"].shift(-1)\n",
    "z[\"rf_fwd\"]  = df[\"rf_monthly\"].shift(-1)\n",
    "z = z.dropna(subset=[\"SPY_fwd\", \"rf_fwd\"])\n",
    "\n",
    "y    = z[\"SPY_fwd\"].values\n",
    "Xall = z[[\"SPX D/P\", \"SPX E/P\"]].values\n",
    "rf_f = z[\"rf_fwd\"].values\n",
    "\n",
    "start = 60\n",
    "rx_list = []\n",
    "\n",
    "for t in range(start, len(z)-1):\n",
    "    y_train = y[:t]\n",
    "    X_train = Xall[:t]\n",
    "    Xc = sm.add_constant(X_train, has_constant=\"add\")\n",
    "    m = sm.OLS(y_train, Xc).fit()\n",
    "\n",
    "    X_t = sm.add_constant(Xall[t].reshape(1, -1), has_constant=\"add\")\n",
    "    yhat = m.predict(X_t)[0]\n",
    "    w_t  = 100 * yhat\n",
    "    rx_t = w_t * y[t]           # strategy return at t+1\n",
    "    rx_list.append(rx_t)\n",
    "\n",
    "rx_excess   = rx - rf\n",
    "mkt_excess  = mkt - rf\n",
    "\n",
    "mean   = rx_excess.mean()\n",
    "vol    = rx_excess.std()\n",
    "sharpe = mean / vol\n",
    "\n",
    "wealth = (1 + rx).cumprod()\n",
    "peak   = np.maximum.accumulate(wealth)\n",
    "mdd    = ((wealth - peak) / peak).min()\n",
    "\n",
    "Xm  = sm.add_constant(mkt_excess, has_constant=\"add\")\n",
    "reg = sm.OLS(rx_excess, Xm).fit()\n",
    "alpha = reg.params[0]\n",
    "beta  = reg.params[1]\n",
    "te    = reg.resid.std()\n",
    "info  = alpha / te\n",
    "\n",
    "print(\"OOS DP+EP strategy:\")\n",
    "print(\"mean:\",   mean)\n",
    "print(\"vol:\",    vol)\n",
    "print(\"Sharpe:\", sharpe)\n",
    "print(\"max drawdown:\", mdd)\n",
    "print(\"alpha:\", alpha)\n",
    "print(\"beta:\",  beta)\n",
    "print(\"information ratio:\", info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f55f9b",
   "metadata": {},
   "source": [
    "The OOS DP+EP strategy performs much worse than the in-sample strategies: its Sharpe ratio falls by more than half (0.078 vs. ~0.15), alpha turns negative, and the information ratio drops from strongly positive to –0.04, indicating no genuine forecasting ability.\n",
    "Drawdowns remain extremely large (–68%), and beta falls to ~0.78, confirming that once we move out of sample the strategy becomes essentially noisily leveraged equity exposure with much weaker risk-adjusted performance than the in-sample results suggested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2c4503",
   "metadata": {},
   "source": [
    "3. **Redo 3.3 with OOS forecasts.** Is the point‑in‑time version of the strategy **riskier**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9815c914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample VaR_5\n",
      "DP: -0.06154457123158455\n",
      "EP: -0.06414378394464915\n",
      "DP+EP+10Y: -0.06521555569005687\n",
      "SPY: -0.07442817951315703\n",
      "GMWAX: -0.04038561221646227\n",
      "\n",
      "OOS VaR_5\n",
      "OOS DP+EP strategy: -0.06054886003833105\n",
      "OOS SPY: -0.07292383167884636\n",
      "OOS GMWAX: -0.0400787099144672\n"
     ]
    }
   ],
   "source": [
    "z_ins = df.join(signals[[\"SPX D/P\", \"SPX E/P\", \"T-Note 10YR\"]], how=\"inner\")\n",
    "z_ins[\"SPY_fwd\"] = z_ins[\"SPY\"].shift(-1)\n",
    "z_ins = z_ins.dropna(subset=[\"SPY_fwd\"])\n",
    "\n",
    "def strat_ins(cols):\n",
    "    X = z_ins[cols]\n",
    "    y = z_ins[\"SPY_fwd\"]\n",
    "    Xc = sm.add_constant(X)\n",
    "    m = sm.OLS(y, Xc).fit()\n",
    "    rhat = m.predict(Xc)\n",
    "    w = 100 * rhat\n",
    "    rx = w * y\n",
    "    return rx.values\n",
    "\n",
    "rx_dp_in  = strat_ins([\"SPX D/P\"])\n",
    "rx_ep_in  = strat_ins([\"SPX E/P\"])\n",
    "rx_3_in   = strat_ins([\"SPX D/P\", \"SPX E/P\", \"T-Note 10YR\"])\n",
    "\n",
    "VaR_dp_in = np.quantile(rx_dp_in, 0.05)\n",
    "VaR_ep_in = np.quantile(rx_ep_in, 0.05)\n",
    "VaR_3_in  = np.quantile(rx_3_in, 0.05)\n",
    "\n",
    "r_mkt_in  = z_ins[\"SPY_fwd\"].values\n",
    "r_gmo_in  = df.loc[z_ins.index, \"GMWAX\"].values\n",
    "VaR_mkt_in = np.quantile(r_mkt_in, 0.05)\n",
    "VaR_gmo_in = np.quantile(r_gmo_in, 0.05)\n",
    "\n",
    "print(\"In-sample VaR_5\")\n",
    "print(\"DP:\", VaR_dp_in)\n",
    "print(\"EP:\", VaR_ep_in)\n",
    "print(\"DP+EP+10Y:\", VaR_3_in)\n",
    "print(\"SPY:\", VaR_mkt_in)\n",
    "print(\"GMWAX:\", VaR_gmo_in)\n",
    "\n",
    "# OOS DP+EP strategy (from your rolling code)\n",
    "z = df.join(signals[[\"SPX D/P\", \"SPX E/P\"]], how=\"inner\")\n",
    "z[\"SPY_fwd\"] = z[\"SPY\"].shift(-1)\n",
    "z[\"rf_fwd\"]  = df[\"rf_monthly\"].shift(-1)\n",
    "z = z.dropna(subset=[\"SPY_fwd\", \"rf_fwd\"])\n",
    "\n",
    "y    = z[\"SPY_fwd\"].values\n",
    "Xall = z[[\"SPX D/P\", \"SPX E/P\"]].values\n",
    "rf_f = z[\"rf_fwd\"].values\n",
    "\n",
    "start = 60\n",
    "rx_list = []\n",
    "\n",
    "for t in range(start, len(z)-1):\n",
    "    y_train = y[:t]\n",
    "    X_train = Xall[:t]\n",
    "    Xc = sm.add_constant(X_train, has_constant=\"add\")\n",
    "    m = sm.OLS(y_train, Xc).fit()\n",
    "    X_t = sm.add_constant(Xall[t].reshape(1, -1), has_constant=\"add\")\n",
    "    yhat = m.predict(X_t)[0]\n",
    "    w_t  = 100 * yhat\n",
    "    rx_t = w_t * y[t]\n",
    "    rx_list.append(rx_t)\n",
    "\n",
    "rx_oos = np.array(rx_list)\n",
    "mkt_oos = y[start:len(z)-1]\n",
    "gmo_oos = df.loc[z.index[start:len(z)-1], \"GMWAX\"].values\n",
    "\n",
    "VaR_oos_strat = np.quantile(rx_oos, 0.05)\n",
    "VaR_oos_mkt   = np.quantile(mkt_oos, 0.05)\n",
    "VaR_oos_gmo   = np.quantile(gmo_oos, 0.05)\n",
    "\n",
    "print(\"\\nOOS VaR_5\")\n",
    "print(\"OOS DP+EP strategy:\", VaR_oos_strat)\n",
    "print(\"OOS SPY:\", VaR_oos_mkt)\n",
    "print(\"OOS GMWAX:\", VaR_oos_gmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d0422b",
   "metadata": {},
   "source": [
    "No: the point-in-time (OOS) version is not meaningfully safer. Its left-tail risk is almost identical to the in-sample strategy (VaR ≈ –6.1% in-sample vs. –6.0% OOS) while max drawdowns stay around –68% and Sharpe and alpha are much worse, so the overall risk–return tradeoff is actually poorer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 EXTRA: ML Forecasts\n",
    "\n",
    "1. **CART.** Re‑do Section 3 using **CART** (e.g., `RandomForestRegressor` from `sklearn.ensemble`). If you want to visualize, try `sklearn.tree`.\n",
    "2. **CART, OOS.** Compute out‑of‑sample stats as in Section 4.\n",
    "3. **Neural Network.** Re‑do Section 3 using a **neural network** (e.g., `MLPRegressor` from `sklearn.neural_network`).\n",
    "4. **NN & CART, OOS.** Compute out‑of‑sample stats as in Section 4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
